
.. Places parent toc into the sidebar

:parenttoc: True

.. include:: ../../includes/big_toc_css.rst

============================
WeakSpot
============================
Weakness detection refers to the process of identifying regions in which a model is likely to underperform or produce incorrect predictions. These weaknesses can arise due to various reasons such as inadequate or biased data, overfitting, the use of inappropriate algorithms, or insufficient model complexity. Identifying and addressing these weaknesses is crucial to improving the accuracy and reliability of the model. In PiML, the weakspot test enables us to identify weak regions of a fitted model, by various slicing techniques, see the details below.


Algorithm Details
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Given a fitted model, we do weakspot test by performing the following steps:

- Specify 1 or 2 slicing features;
- Segment the data into regions with 1 or 2 slicing features of interest;
- Perform an unsupervised or supervised binning of the chosen slicing features;
- Evaluate the performance metric of each binning segment;
- Filter out weak regions subject to the performance threshold and minimum sample constraints.

In weakspot, we have three built-in methods to detect weak regions, i.e., histogram slicing, tree slicing, and ensemble tree slicing.

**Histogram Slicing**

This is an unsupervised binning method in which we perform equal-space binning on the features of interest. The number of bins is fixed at 10. However as the number of unique values is less than 10, we use the unique values as the split points instead. As two slicing features are specified, we first perform histogram binning on one feature, and then, for each bin, do histogram binning on the second feature.

If some connected bins are identified as weak regions, we would merge them into a single bin. The merging process is straightforward for one slicing feature. However, when there are two slicing features, we condition one dimension and merge the weak regions along the other dimension.

**Tree Slicing**

This is a supervised binning method. First, calculate the metric for each sample, for instance, the square error for MSE, absolute error for MAE, or correct or incorrect status for accuracy score. Then, fit a decision tree model (`max_depth=3` and `min_samples_leaf` as the minimum sample size) using the features of interest as predictors and the individual metrics for each sample as the response. The decision tree is used to generate bins, and the performance of each bin is evaluated.

**Ensemble Tree Slicing**

This method is similar to that of tree slicing. Given the metrics of individual samples, it uses xgboost (`max_depth=2`, `n_estimaors=100`, `tree_method="hist"`, `max_bin=20`) to generate bins rather than trees. The binning results of xgboost are usually more granular. 

.. note::

    The supervised binning methods, i.e., tree slicing and ensemble tree slicing, can only be used as the metric is additive. That is, the metric of the whole sample can be calculated by summing up the metric of individual samples. For example, the "MSE", "MAE, and "ACC" (accuracy score) metrics are additive, but "R2", "AUC", and "F1" metrics are not. The default metric is "MSE" for regression tasks and ACC for classification tasks. The available metrics are "MSE", "MAE", "R2", "ACC", "AUC", and "F1". 


Usage
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
For demonstration purposes, we consider an XGB2 model on the TaiwanCredit data. Weakspot assessment can be done using `model_diagnose`. To evaluate weak regions, set `show` to "weakspot". In addition, the following parameters provide more flexibility.

- `slice_method`: This option is used to choose which slicing method to use, available options include "histogram", "tree", and "xgb", which correspond to the three previously mentioned slicing methods. The default is "histogram".

- `slice_features`: This is the argument for specifying the list of slicing features. To use weakspot, 1 or 2 slicing features should be specified, otherwise, a warning message would show up. 

- `bins`: This is the number of bins for histogram slicing. By default, it is set to 10.

- `metric`: The performance metrics, including "MSE", "MAE", and "R2" for regression; "ACC", "AUC", and "F1" for classification. The default metric is "MSE" for regression tasks and "ACC" for classification tasks.

- `threshold`: This is the performance metric threshold ratio to distinguish weak and good regions. By default, it is set to 1.1, which is equivalent to a 10% performance drop compared to the average. For instance, if the AUC of the whole sample (the train or test set) is 0.8, then the threshold is 0.8 / 1.1 = 0.723. Regions with AUC less than 0.723 will be treated as weak regions. For metrics like MSE for regression, the threshold is instead 0.8 * 1.1 = 0.88 (where 0.8 is the average metric of the whole sample), as the MSE metric is the smaller the better. Regions with MSE greater than 0.88 will be treated as weak regions.

- `min_samples`: The minimum sample size for a weak region, and the default value is 20. Regions with a sample size of less than 20 will be ignored.

- `use_test`: This boolean argument is used to switch between train and test sets. By default, it is set to False (training data). To use the testing data, set `use_test` to True.

One-way WeakSpot Plot
""""""""""""""""""""""""""
In the following demo, we identify weak regions of the testing data (`use_test=True`). We set the slice method to be "histogram", threshold ratio to be 1.1, minimum sample size as 100, and focus on a single slicing feature `PAY_1`.

.. jupyter-input::

    results = exp.model_diagnose(model="XGB2", show="weakspot", slice_method="histogram", 
                            slice_features=["PAY_1"], threshold=1.1, min_samples=100, metric="ACC",
                            use_test=True, return_data=True, original_scale=True, figsize=(5, 4))

.. figure:: ../../auto_examples/testing/images/sphx_glr_plot_1_weakspot_cls_001.png
   :target: ../../auto_examples/testing/plot_1_weakspot_cls.html
   :align: left

The plot above shows that one weak region is detected, for `PAY_1` between 0.2 and 0.4. The red dotted line represents the performance threshold (around 0.75) of weak regions, determined by the average metric (around 0.82) divided by the user-specified argument `threshold` (1.1). The weak region is annotated with its weak region number. On the x-axis, we have our variable of interest, and on the y-axis, the density and the accuracy score of each segment. In the density plot, the "Above threshold" and "Below threshold" denote the population with a prediction error greater or less than the threshold. Note that as we use metrics that are not additive, e.g., "AUC", "F1" for classification, or "R2" for regression, the density plot does not show the "Above threshold" and "Below threshold" labels.

The detailed information of weak regions can be found in the returned weakspot table, as we set `return_data` to True. 

.. jupyter-input::

    results.data

.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
            align: left;
        }

        .dataframe tbody tr th {
            vertical-align: top;
            align: left;
        }

        .dataframe thead th {
            text-align: right;
            align: left;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>[PAY_1</th>
          <th>PAY_1)</th>
          <th>#Test</th>
          <th>#Train</th>
          <th>test_ACC</th>
          <th>train_ACC</th>
          <th>Gap</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>0</th>
          <td>0.2</td>
          <td>0.4</td>
          <td>1265</td>
          <td>5090</td>
          <td>0.695652</td>
          <td>0.689587</td>
          <td>0.006065</td>
        </tr>
      </tbody>
    </table>
    </div>
    </div>

The table above shows the weak regions of the testing data. It contains the following columns:

    - `[feature_name`: The lower bound of the slicing feature;
    - `feature_name)`: The upper bound of the slicing feature;
    - `#Test`: The number of samples in the testing set;
    - `#Train`: The number of samples in the training set;
    - `test_metric`: The performance metric of the weak region on the testing set;
    - `train_metric`: The performance metric of the weak region on the training set;
    - `Gap`: The difference between the testing and the training performance metric.

Note that if no weak region is detected, then a message saying "No weak regions detected." will be displayed, and the `results` object will become `None`. Note that as there exist multiple weak regions, the order of weak regions is determined by the gap between the testing and the training performance metrics.

Two-way WeakSpot Plot
""""""""""""""""""""""""""
In the following demo, we identify weak regions of the testing data (`use_test=True`) using two slicing features, i.e., `PAY_1` and `PAY_2`. We set the minimum sample size as 100 and still use the histogram slicing.

.. jupyter-input::
     
    results = exp.model_diagnose(model="XGB2", show="weakspot", slice_method="histogram", 
                           slice_features=["PAY_1", "PAY_2"], threshold=1.1, min_samples=100, metric="ACC",
                           use_test=True, return_data=True, original_scale=True, figsize=(5, 4))

.. figure:: ../../auto_examples/testing/images/sphx_glr_plot_1_weakspot_cls_002.png
   :target: ../../auto_examples/testing/plot_1_weakspot_cls.html
   :align: left

.. jupyter-input::

    results.data

.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: left;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>[PAY_1</th>
          <th>PAY_1)</th>
          <th>[PAY_2</th>
          <th>PAY_2)</th>
          <th>#Test</th>
          <th>#Train</th>
          <th>test_ACC</th>
          <th>train_ACC</th>
          <th>Gap</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>0</th>
          <td>0.3</td>
          <td>0.4</td>
          <td>0.000000</td>
          <td>0.250000</td>
          <td>191</td>
          <td>800</td>
          <td>0.691099</td>
          <td>0.678750</td>
          <td>0.012349</td>
        </tr>
        <tr>
          <th>1</th>
          <td>0.2</td>
          <td>0.3</td>
          <td>0.111111</td>
          <td>0.222222</td>
          <td>268</td>
          <td>956</td>
          <td>0.727612</td>
          <td>0.717573</td>
          <td>0.010039</td>
        </tr>
        <tr>
          <th>2</th>
          <td>0.3</td>
          <td>0.4</td>
          <td>0.375000</td>
          <td>0.625000</td>
          <td>322</td>
          <td>1354</td>
          <td>0.720497</td>
          <td>0.717134</td>
          <td>0.003362</td>
        </tr>
        <tr>
          <th>3</th>
          <td>0.2</td>
          <td>0.3</td>
          <td>0.333333</td>
          <td>0.555556</td>
          <td>351</td>
          <td>1430</td>
          <td>0.612536</td>
          <td>0.614685</td>
          <td>-0.002150</td>
        </tr>
        <tr>
          <th>4</th>
          <td>0.0</td>
          <td>0.1</td>
          <td>0.375000</td>
          <td>0.750000</td>
          <td>82</td>
          <td>360</td>
          <td>0.621951</td>
          <td>0.625000</td>
          <td>-0.003049</td>
        </tr>
      </tbody>
    </table>
    </div>
    </div>

This demo considers two variables. Under this setting, the plot and the summary table indicate 5 weak regions. For instance, region 0 recorded 191 testing and 800 training samples with `PAY_1` in [0.3, 1.4) and `PAY_AMT2` in [0.00, 0.25). In addition, the table contains information such as the testing and the training accuracy score of the samples in each region and the gap between the testing and the training ACC score.


Examples
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

.. topic:: Example 1: BikeSharing

  The first example below demonstrates how to use PiML with its high-code APIs for developing machine learning models for the BikeSharing data from the UCI repository, which consists of 17,389 samples of hourly counts of rental bikes in Capital bikeshare system; see details. The response `cnt` (hourly bike rental counts) is continuous and it is a regression problem.
 
 * :ref:`sphx_glr_auto_examples_testing_plot_1_weakspot_reg.py`

.. topic:: Examples 2: Taiwan Credit

  The second example below demonstrates how to use PiMLâ€™s high-code APIs for the TaiwanCredit dataset from the UCI repository. This dataset comprises the credit card details of 30,000 clients in Taiwan from April 2005 to September 2005, and more information can be found on the TaiwanCreditData website. The data can be loaded directly into PiML, although it requires some preprocessing. The FlagDefault variable serves as the response for this classification problem.
    
 * :ref:`sphx_glr_auto_examples_testing_plot_1_weakspot_cls.py`
