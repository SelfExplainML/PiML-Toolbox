<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>

  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  
  <title>PiML Toolbox</title>
  

  
  <link rel="shortcut icon" href="../../_static/favicon.ico"/>
  

  <link rel="stylesheet" href="../../_static/css/vendor/bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/plot_directive.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/jupyter-sphinx.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/thebelab.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery-rendered-html.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-OERcA2EqjJCMA+/3y+gxIOqMEjwtxJY7qPCqsdltbNJuaOe923+mo//f6V8Qbsw3" crossorigin="anonymous"></script>
<script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
<script src="../../_static/jquery.js"></script>
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/sphinx_highlight.js"></script>
        <script src="../../_static/thebelab-helper.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@^1.0.1/dist/embed-amd.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
    <script src="../../_static/js/theme.js"></script>

</head>

<body class="wy-body-for-nav">

  


<nav id="navbar" class="sk-docs-navbar navbar navbar-expand-md navbar-light bg-light py-0">
  <div class="container-fluid sk-docs-container px-0">
      <a class="navbar-brand py-0" href="../../index.html">
        <img
          class="sk-brand-img"
          src="../../_static/piml-logo.png"
          alt="logo"/>
      </a>
    <button
      id="sk-navbar-toggler"
      class="navbar-toggler"
      type="button"
      data-toggle="collapse"
      data-target="#navbarSupportedContent"
      aria-controls="navbarSupportedContent"
      aria-expanded="false"
      aria-label="Toggle navigation"
    >
      <span class="navbar-toggler-icon"></span>
    </button>

    <div class="sk-navbar-collapse collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav mr-auto">
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../../install.html">Install</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../../user_guide.html">User Guide</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../../modules/classes.html">API</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../../auto_examples/index.html">Examples</a>
        </li>
     </ul>
      <div id="searchbox" role="search">
          <div class="searchformwrapper">
          <form class="search" action="../../search.html" method="get">
            <input class="sk-search-text-input" type="text" name="q" aria-labelledby="searchlabel" />
            <input class="sk-search-text-btn" type="submit" value="Go" />
          </form>
          </div>
      </div>
    </div>
  </div>
</nav>
  <div class="d-flex" id="sk-doc-wrapper">
      <input type="checkbox" name="sk-toggle-checkbox" id="sk-toggle-checkbox">
      <label id="sk-sidemenu-toggle" class="sk-btn-toggle-toc btn sk-btn-primary" for="sk-toggle-checkbox">Toggle Menu</label>
      <div id="sk-sidebar-wrapper" class="border-right">
        <div class="sk-sidebar-toc-wrapper">
          <div class="sk-sidebar-toc-logo">
            <a href="../../index.html">
              <img
                class="sk-brand-img"
                src="../../_static/piml-logo.png"
                alt="logo"/>
            </a>
          </div>
          <!--div class="btn-group w-100 mb-2" role="group" aria-label="rellinks">
              <a href="../testing.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="6. Diagnostic Suite">Prev</a><a href="../testing.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="6. Diagnostic Suite">Up</a>
              <a href="weakspot.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="6.2. WeakSpot">Next</a>
          </div-->
              <div class="sk-sidebar-toc">
              
                <ul>
                
                
                
                
                
                
                <li>
                  <a href="../../user_guide.html" class="sk-toc-active">User Guide</a>
                </li>
                <ul>
                
                  <li>
                    <a href="../introduction.html" class="">1. Introduction</a>
                    
                  </li>
                
                  <li>
                    <a href="../data.html" class="">2. Data Pipeline</a>
                    
                  </li>
                
                  <li>
                    <a href="../extmodels.html" class="">3. Black-box Models</a>
                    
                  </li>
                
                  <li>
                    <a href="../explainability.html" class="">4. Post-hoc Explainability</a>
                    
                  </li>
                
                  <li>
                    <a href="../models.html" class="">5. Interpretable Models</a>
                    
                  </li>
                
                  <li>
                    <a href="../testing.html" class="sk-toc-active">6. Diagnostic Suite</a>
                    
                    <ul>
                      
                        <li class="sk-toctree-l3">
                          <a href="">6.1. Accuracy</a>
                        </li>
                      
                        <li class="sk-toctree-l3">
                          <a href="weakspot.html">6.2. WeakSpot</a>
                        </li>
                      
                        <li class="sk-toctree-l3">
                          <a href="overfit.html">6.3. Overfit</a>
                        </li>
                      
                        <li class="sk-toctree-l3">
                          <a href="reliability.html">6.4. Reliability</a>
                        </li>
                      
                        <li class="sk-toctree-l3">
                          <a href="robustness.html">6.5. Robustness</a>
                        </li>
                      
                        <li class="sk-toctree-l3">
                          <a href="resilience.html">6.6. Resilience</a>
                        </li>
                      
                        <li class="sk-toctree-l3">
                          <a href="fairness.html">6.7. Fairness</a>
                        </li>
                      
                    </ul>
                    
                  </li>
                
                  <li>
                    <a href="../comparison.html" class="">7. Model Comparison</a>
                    
                  </li>
                
                  <li>
                    <a href="../cases.html" class="">8. Case Studies</a>
                    
                  </li>
                
                </ul>
                
                
                
                
                </ul>
              </div>
        </div>
      </div>
      <div id="sk-page-content-wrapper">
        <div class="sk-page-content container-fluid body px-md-3" role="main">
          
  <style type="text/css">
  div.body div.toctree-wrapper ul {
      padding-left: 0;
  }

  div.body li.toctree-l1 {
      padding: 0 0 0.5em 0;
      list-style-type: none;
      font-size: 150%;
      font-weight: bold;
  }

  div.body li.toctree-l2 {
      font-size: 70%;
      list-style-type: square;
      font-weight: normal;
      margin-left: 40px;
  }

  div.body li.toctree-l3 {
      font-size: 85%;
      list-style-type: circle;
      font-weight: normal;
      margin-left: 40px;
  }

  div.body li.toctree-l4 {
      margin-left: 40px;
  }

</style><section id="accuracy">
<h1><span class="section-number">6.1. </span>Accuracy<a class="headerlink" href="#accuracy" title="Permalink to this heading">¶</a></h1>
<p>This section serves as a user guide for utilizing PiML to assess the performance of our model using essential metrics for regression and binary classification tasks. In PiML, we can use the <code class="docutils literal notranslate"><span class="pre">model_diagnose</span></code> function to assess the performance of our model. Note that all the metrics mentioned in this section are based on the functions provided by <a class="reference external" href="https://scikit-learn.org/stable/modules/model_evaluation.html">sklearn_metrics</a>.</p>
<section id="regression-tasks">
<h2><span class="section-number">6.1.1. </span>Regression Tasks<a class="headerlink" href="#regression-tasks" title="Permalink to this heading">¶</a></h2>
<p>Available metrics for regression tasks include mean squared error (MSE), mean absolute error (MAE), and R-squared (R2).</p>
<ul class="simple">
<li><p><strong>Mean Squared Error</strong> (MSE): The squared difference between the actual and predicted values. The mean squared error is the average of the squared errors.</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{align}
    MSE = \frac{1}{n}\sum_{i=1}^{n}(y_{i} - \hat{y}_{i})^{2} \tag{1}
\end{align}\]</div>
<ul class="simple">
<li><p><strong>Mean absolute Error</strong> (MAE): The absolute value of the difference between the actual and predicted values. The mean absolute error is the average of the absolute errors.</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{align}
    MAE = \frac{1}{n}\sum_{i=1}^{n}|y_{i} - \hat{y}_{i}|. \tag{2}
\end{align}\]</div>
<ul class="simple">
<li><p><strong>R-squared</strong> (R2): The proportion of variance of the response variable that can be explained by the model.</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{align}
    R2 = 1-\frac{\sum_{i=1}^{n}(y_{i} - \hat{y}_{i})^{2} } {\sum_{i=1}^{n}(y_{i} - \bar{y})^{2} }\tag{3}
\end{align}\]</div>
<section id="accuracy-table">
<h3><span class="section-number">6.1.1.1. </span>Accuracy Table<a class="headerlink" href="#accuracy-table" title="Permalink to this heading">¶</a></h3>
<p>By setting <code class="docutils literal notranslate"><span class="pre">show</span></code> to “accuracy_table”, we can generate a summary table for different metrics. The code below shows how to generate the accuracy table for a fitted XGB2 model on the bike sharing dataset.</p>
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">exp</span><span class="o">.</span><span class="n">model_diagnose</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;XGB2&quot;</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="s1">&#39;accuracy_table&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
</div>
</div>
<div class="output_subarea output_html rendered_html output_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>MSE</th>
      <th>MAE</th>
      <th>R2</th>
    </tr>
    <tr>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Train</th>
      <td>0.0087</td>
      <td>0.0649</td>
      <td>0.7469</td>
    </tr>
    <tr>
      <th>Test</th>
      <td>0.0092</td>
      <td>0.0668</td>
      <td>0.7368</td>
    </tr>
    <tr>
      <th>Gap</th>
      <td>0.0005</td>
      <td>0.0018</td>
      <td>-0.0101</td>
    </tr>
  </tbody>
</table><p>In this table, we show the metrics for train and test sets, respectively, as well as the gap between these two sets. A good model is characterized by a low MAE or MSE (close to zero) and R2 value close to 1. Ideally, the gap should be small, indicating that the model is not overfitting. Note that the value of R2 is always between 0 and 1 for training set. However, it is possible to have negative values for testing set.</p>
</section>
<section id="residual-plot">
<h3><span class="section-number">6.1.1.2. </span>Residual Plot<a class="headerlink" href="#residual-plot" title="Permalink to this heading">¶</a></h3>
<p>Residual is the difference between the actual response and the predicted response values. A residual plot displays the relationship of residuals against a feature of interest. The ideal residual plot, called the null residual plot, shows a random scatter of points forming an approximately constant-width band around the identity line. In PiML, we can generate residual plots for the testing set by setting <code class="docutils literal notranslate"><span class="pre">show</span></code> to “residual_plot” and specifying the <code class="docutils literal notranslate"><span class="pre">target_feature</span></code> of interest, as shown below. In addition, we can also set <code class="docutils literal notranslate"><span class="pre">original_scale</span></code> to True to display the residual values in the original scale. And the argument <code class="docutils literal notranslate"><span class="pre">use_test</span></code> (default=False means using training set) can be set to True to use the testing set for generating the residual plot.</p>
<p><strong>Numerical Features</strong></p>
<p>The first example below displays the residual plot for a numerical feature, i.e., <code class="docutils literal notranslate"><span class="pre">hr</span></code>, which is a line chart. Upon analyzing the plot, it becomes apparent that there is a notable heterogeneity in the residuals across different hours of the day. Specifically, the range of residuals observed during rush hours is significantly greater than that of non-peak hours. That is reasonable as the demand for bike sharing is much higher during rush hours than non-peak hours, and it is relatively hard to make predictions for rush hours.</p>
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">exp</span><span class="o">.</span><span class="n">model_diagnose</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;XGB2&quot;</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="s2">&quot;accuracy_residual&quot;</span><span class="p">,</span> <span class="n">target_feature</span><span class="o">=</span><span class="s2">&quot;hr&quot;</span><span class="p">,</span>
                   <span class="n">use_test</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">original_scale</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
</div>
</div>
<figure class="align-left">
<a class="reference external image-reference" href="../../auto_examples/testing/plot_0_accuracy_reg.html"><img alt="../../_images/sphx_glr_plot_0_accuracy_reg_001.png" src="../../_images/sphx_glr_plot_0_accuracy_reg_001.png" /></a>
</figure>
<p><strong>Categorical Features</strong></p>
<p>The next example below displays the residual plot for a categorical feature, i.e., <code class="docutils literal notranslate"><span class="pre">season</span></code>, which is a bar chart. The plot shows that the residuals are more or less evenly distributed across different seasons, which is a good sign.</p>
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">exp</span><span class="o">.</span><span class="n">model_diagnose</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;XGB2&quot;</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="s2">&quot;accuracy_residual&quot;</span><span class="p">,</span> <span class="n">target_feature</span><span class="o">=</span><span class="s2">&quot;season&quot;</span><span class="p">,</span>
                   <span class="n">use_test</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">original_scale</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
</div>
</div>
<figure class="align-left">
<a class="reference external image-reference" href="../../auto_examples/testing/plot_0_accuracy_reg.html"><img alt="../../_images/sphx_glr_plot_0_accuracy_reg_002.png" src="../../_images/sphx_glr_plot_0_accuracy_reg_002.png" /></a>
</figure>
<p><strong>Response Feature</strong></p>
<p>In addition to generating residual plots for input features, we can also generate residual plots against the response feature (<code class="docutils literal notranslate"><span class="pre">cnt</span></code> in the BikeSharing data), as shown below. The plot illustrates a noteworthy disparity in the residuals across various values of the response feature. Specifically, there appears to be a positive correlation between the residuals and the response, indicating that additional features may be necessary to enhance model performance.</p>
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">exp</span><span class="o">.</span><span class="n">model_diagnose</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;XGB2&quot;</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="s2">&quot;accuracy_residual&quot;</span><span class="p">,</span> <span class="n">target_feature</span><span class="o">=</span><span class="s2">&quot;cnt&quot;</span><span class="p">,</span>
                   <span class="n">use_test</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
</div>
</div>
<figure class="align-left">
<a class="reference external image-reference" href="../../auto_examples/testing/plot_0_accuracy_reg.html"><img alt="../../_images/sphx_glr_plot_0_accuracy_reg_003.png" src="../../_images/sphx_glr_plot_0_accuracy_reg_003.png" /></a>
</figure>
<p><strong>Predicted Value</strong></p>
<p>Finally, the residual plot against the predicted values is shown below. To generate this plot, the argument <code class="docutils literal notranslate"><span class="pre">target_feature</span></code> should be set as the response feature name + “_predict”. From this plot, we can observe a positive relationship between the predicted value and the variation of residuals. This finding is consistent with the observations made from the previous residual plot, which suggested that predicting bike sharing during rush hours is more challenging than during non-peak hours. Additionally, we notice that the scatter plot appears to be bounded at the bottom by the line <span class="math notranslate nohighlight">\(x+y=0\)</span>. This boundary exists because the predicted values (<span class="math notranslate nohighlight">\(x\)</span>) plus the residuals (<span class="math notranslate nohighlight">\(y\)</span>) equal the response variable, and the minimum value of bike sharing is zero.</p>
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">exp</span><span class="o">.</span><span class="n">model_diagnose</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;XGB2&quot;</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="s2">&quot;accuracy_residual&quot;</span><span class="p">,</span> <span class="n">target_feature</span><span class="o">=</span><span class="s2">&quot;cnt_predict&quot;</span><span class="p">,</span>
                   <span class="n">use_test</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
</div>
</div>
<figure class="align-left">
<a class="reference external image-reference" href="../../auto_examples/testing/plot_0_accuracy_reg.html"><img alt="../../_images/sphx_glr_plot_0_accuracy_reg_004.png" src="../../_images/sphx_glr_plot_0_accuracy_reg_004.png" /></a>
</figure>
</section>
</section>
<section id="binary-classification">
<h2><span class="section-number">6.1.2. </span>Binary Classification<a class="headerlink" href="#binary-classification" title="Permalink to this heading">¶</a></h2>
<p>For binary classification tasks, the following metrics are available.</p>
<ul class="simple">
<li><p><strong>Accuracy-score (ACC)</strong>: The accuracy score is a widely used metric for evaluating classification models, computed by dividing the number of correctly classified samples by the total number of samples. However, when dealing with imbalanced datasets, accuracy alone may not be the best metric to evaluate model performance. In such cases, we need to consider additional metrics such as AUC and F1-score.</p></li>
<li><p><strong>Area Under the ROC Curve (AUC)</strong>: is a valuable metric for summarizing the performance of a classifier. Its values range from 0 to 1, with a model whose predictions are entirely incorrect having an AUC of 0.0, and a model whose predictions are entirely accurate having an AUC of 1.0. A random classifier would have an AUC of approximately 0.5, indicating that it is no better than guessing. AUC provides a helpful measure of how well the classifier distinguishes between positive and negative classes and can be used to compare the performance of different models.</p></li>
<li><p><strong>F1-score (F1)</strong>: The F1 score is the harmonic mean of precision and recall, as follows.</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{align}
   F1 = 2\frac{Precision \cdot Recall}{Precision+Recall}=\frac{2TP}{2TP+FP+FN} \tag{4}
\end{align}\]</div>
<section id="id1">
<h3><span class="section-number">6.1.2.1. </span>Accuracy Table<a class="headerlink" href="#id1" title="Permalink to this heading">¶</a></h3>
<p>The accuracy table for a binary classification task includes three metrics, i.e., “ACC”, “AUC”, and “F1”. The following example shows the usage of the accuracy table for a fitted XGB2 model on the TaiwanCredit dataset.</p>
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">exp</span><span class="o">.</span><span class="n">model_diagnose</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;XGB2&quot;</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="s2">&quot;accuracy_table&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
</div>
</div>
<div class="output_subarea output_html rendered_html output_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ACC</th>
      <th>AUC</th>
      <th>Recall</th>
      <th>Precision</th>
      <th>F1</th>
    </tr>
    <tr>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Train</th>
      <td>0.8223</td>
      <td>0.7970</td>
      <td>0.3617</td>
      <td>0.6924</td>
      <td>0.4751</td>
    </tr>
    <tr>
      <th>Test</th>
      <td>0.8288</td>
      <td>0.7732</td>
      <td>0.3624</td>
      <td>0.7015</td>
      <td>0.4779</td>
    </tr>
    <tr>
      <th>Gap</th>
      <td>0.0066</td>
      <td>-0.0237</td>
      <td>0.0007</td>
      <td>0.0091</td>
      <td>0.0027</td>
    </tr>
  </tbody>
</table>
</div>
</div><p>The table resembles that of regression tasks, but instead uses “ACC”, “AUC”, and “F1” metrics for binary classification. In all cases, a larger value indicates a better model. The “Gap” column shows the difference between the training and testing metrics, with a smaller gap indicating less overfitting and a more reliable model.</p>
</section>
<section id="id2">
<h3><span class="section-number">6.1.2.2. </span>Residual Plot<a class="headerlink" href="#id2" title="Permalink to this heading">¶</a></h3>
<p>This plot shows prediction residual against a variable of interest. Similar to the residual plot of regression tasks, we set parameter <code class="docutils literal notranslate"><span class="pre">show</span></code> to “residual_plot” and also input the feature name in <code class="docutils literal notranslate"><span class="pre">target_feature</span></code>.</p>
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">exp</span><span class="o">.</span><span class="n">model_diagnose</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;XGB2&quot;</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="s2">&quot;residual_plot&quot;</span><span class="p">,</span> <span class="n">target_feature</span><span class="o">=</span><span class="s2">&quot;PAY_1&quot;</span><span class="p">,</span>
                   <span class="n">use_test</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">original_scale</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
</div>
</div>
<figure class="align-left">
<a class="reference external image-reference" href="../../auto_examples/testing/plot_0_accuracy_cls.html"><img alt="../../_images/sphx_glr_plot_0_accuracy_cls_002.png" src="../../_images/sphx_glr_plot_0_accuracy_cls_002.png" /></a>
</figure>
<p>This plot shows the absoluate difference between the predicted probability and the actual response (0 or 1). As the response variable is binary, we plot the absoluate residuals for class 0 and class 1 separately. Moreover, a smoothing curve is added for each class, which is estimated by the locally weighted scatterplot smoothing (<a class="reference external" href="https://en.wikipedia.org/wiki/Local_regression">Lowess</a>) estimator. Note that the feature of interest can be either input feature, the response variable, or the predicted probability. See the example in the <a class="reference external" href="accuracy.html#residual-plot">regression</a> task above for more details.</p>
</section>
<section id="accuracy-plot">
<h3><span class="section-number">6.1.2.3. </span>Accuracy Plot<a class="headerlink" href="#accuracy-plot" title="Permalink to this heading">¶</a></h3>
<p>To evaluate the performance of a binary classification model, we present an additional plot in addition to the accuracy table and residual plot used in regression tasks. This plot can be generated by setting <code class="docutils literal notranslate"><span class="pre">show</span></code> to “accuracy_plot”. It consists of three subplots that display the confusion matrix, ROC curve, and precision-recall curve on the testing set. This plot provides a comprehensive view of the model’s performance, enabling a more thorough evaluation of its accuracy, sensitivity, and specificity.</p>
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">exp</span><span class="o">.</span><span class="n">model_diagnose</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;XGB2&quot;</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="s2">&quot;accuracy_plot&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
</div>
</div>
<figure class="align-left">
<a class="reference external image-reference" href="../../auto_examples/testing/plot_0_accuracy_cls.html"><img alt="../../_images/sphx_glr_plot_0_accuracy_cls_001.png" src="../../_images/sphx_glr_plot_0_accuracy_cls_001.png" /></a>
</figure>
<ul class="simple">
<li><p>The left panel shows the confusion matrix, a valuable tool for evaluating classification model performance. The diagonal elements indicate the number of instances where the predicted label is the same as the true label, while the off-diagonal elements represent mislabeled instances. A higher value on the diagonal indicates better performance and more accurate predictions.</p></li>
<li><p>In the middle panel, the ROC curve illustrates the diagnostic ability of a binary classifier by plotting the true positive rate (TPR) against the false positive rate (FPR) at various threshold settings. This plot helps determine the optimal threshold for classifying instances and assessing the tradeoff between sensitivity and specificity.</p></li>
<li><p>The right panel displays the precision-recall curve, a useful measure for evaluating models when classes are imbalanced. High recall but low precision means that the model is correctly identifying a large number of positive instances (true positives), but it also includes many irrelevant instances. In contrast, low recall but high precision means that the model is correctly identifying a smaller proportion of positive instances (true positives), but the instances it identifies as positive are more likely to be true positives. This plot helps determine the optimal threshold for classifying instances and assessing the tradeoff between precision and recall.</p></li>
</ul>
</section>
</section>
<section id="examples">
<h2><span class="section-number">6.1.3. </span>Examples<a class="headerlink" href="#examples" title="Permalink to this heading">¶</a></h2>
<div class="topic">
<p class="topic-title">Example 1: BikeSharing</p>
<blockquote>
<div><p>The first example below demonstrates how to use PiML with its high-code APIs for developing machine learning models for the BikeSharing data from the UCI repository, which consists of 17,389 samples of hourly counts of rental bikes in Capital bikeshare system; see details. The response <code class="docutils literal notranslate"><span class="pre">cnt</span></code> (hourly bike rental counts) is continuous and it is a regression problem.</p>
</div></blockquote>
<ul class="simple">
<li><p><a class="reference internal" href="../../auto_examples/testing/plot_0_accuracy_reg.html#sphx-glr-auto-examples-testing-plot-0-accuracy-reg-py"><span class="std std-ref">Accuracy: Regression</span></a></p></li>
</ul>
</div>
<div class="topic">
<p class="topic-title">Examples 2: Taiwan Credit</p>
<blockquote>
<div><p>The second example below demonstrates how to use PiML’s high-code APIs for the TaiwanCredit dataset from the UCI repository. This dataset comprises the credit card details of 30,000 clients in Taiwan from April 2005 to September 2005, and more information can be found on the TaiwanCreditData website. The data can be loaded directly into PiML, although it requires some preprocessing. The FlagDefault variable serves as the response for this classification problem.</p>
</div></blockquote>
<ul class="simple">
<li><p><a class="reference internal" href="../../auto_examples/testing/plot_0_accuracy_cls.html#sphx-glr-auto-examples-testing-plot-0-accuracy-cls-py"><span class="std std-ref">Accuracy: Classification</span></a></p></li>
</ul>
</div>
</section>
</section>


        </div>
      <div class="container">
        <footer class="sk-content-footer">
              &copy; Copyright 2022-, PiML-Toolbox authors.
            <a href="../../_sources/guides/testing/accuracy.rst.txt" rel="nofollow">Show this page source</a>
        </footer>
      </div>
    </div>
  </div>


  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(false);
      });
      
      const tooltipTriggerList = document.querySelectorAll('[data-bs-toggle="tooltip"]')
      const tooltipList = [...tooltipTriggerList].map(tooltipTriggerEl => new bootstrap.Tooltip(tooltipTriggerEl))
  </script>

<script>
$(document).ready(function() {
    /* Add a [>>>] button on the top-right corner of code samples to hide
     * the >>> and ... prompts and the output and thus make the code
     * copyable. */
    var div = $('.highlight-python .highlight,' +
                '.highlight-python3 .highlight,' +
                '.highlight-pycon .highlight,' +
		'.highlight-default .highlight')
    var pre = div.find('pre');

    // get the styles from the current theme
    pre.parent().parent().css('position', 'relative');
    var hide_text = 'Hide prompts and outputs';
    var show_text = 'Show prompts and outputs';

    // create and add the button to all the code blocks that contain >>>
    div.each(function(index) {
        var jthis = $(this);
        if (jthis.find('.gp').length > 0) {
            var button = $('<span class="copybutton">&gt;&gt;&gt;</span>');
            button.attr('title', hide_text);
            button.data('hidden', 'false');
            jthis.prepend(button);
        }
        // tracebacks (.gt) contain bare text elements that need to be
        // wrapped in a span to work with .nextUntil() (see later)
        jthis.find('pre:has(.gt)').contents().filter(function() {
            return ((this.nodeType == 3) && (this.data.trim().length > 0));
        }).wrap('<span>');
    });

    // define the behavior of the button when it's clicked
    $('.copybutton').click(function(e){
        e.preventDefault();
        var button = $(this);
        if (button.data('hidden') === 'false') {
            // hide the code output
            button.parent().find('.go, .gp, .gt').hide();
            button.next('pre').find('.gt').nextUntil('.gp, .go').css('visibility', 'hidden');
            button.css('text-decoration', 'line-through');
            button.attr('title', show_text);
            button.data('hidden', 'true');
        } else {
            // show the code output
            button.parent().find('.go, .gp, .gt').show();
            button.next('pre').find('.gt').nextUntil('.gp, .go').css('visibility', 'visible');
            button.css('text-decoration', 'none');
            button.attr('title', hide_text);
            button.data('hidden', 'false');
        }
    });

	/*** Add permalink buttons next to glossary terms ***/
	$('dl.glossary > dt[id]').append(function() {
		return ('<a class="headerlink" href="#' +
			    this.getAttribute('id') +
			    '" title="Permalink to this term">¶</a>');
	});
  /*** Hide navbar when scrolling down ***/
  // Returns true when headerlink target matches hash in url
  (function() {
    hashTargetOnTop = function() {
        var hash = window.location.hash;
        if ( hash.length < 2 ) { return false; }

        var target = document.getElementById( hash.slice(1) );
        if ( target === null ) { return false; }

        var top = target.getBoundingClientRect().top;
        return (top < 2) && (top > -2);
    };

    // Hide navbar on load if hash target is on top
    var navBar = document.getElementById("navbar");
    var navBarToggler = document.getElementById("sk-navbar-toggler");
    var navBarHeightHidden = "-" + navBar.getBoundingClientRect().height + "px";
    var $window = $(window);

    hideNavBar = function() {
        navBar.style.top = navBarHeightHidden;
    };

    showNavBar = function() {
        navBar.style.top = "0";
    }

    if (hashTargetOnTop()) {
        hideNavBar()
    }

    var prevScrollpos = window.pageYOffset;
    hideOnScroll = function(lastScrollTop) {
        if (($window.width() < 768) && (navBarToggler.getAttribute("aria-expanded") === 'true')) {
            return;
        }
        if (lastScrollTop > 2 && (prevScrollpos <= lastScrollTop) || hashTargetOnTop()){
            hideNavBar()
        } else {
            showNavBar()
        }
        prevScrollpos = lastScrollTop;
    };

    /*** high performance scroll event listener***/
    var raf = window.requestAnimationFrame ||
        window.webkitRequestAnimationFrame ||
        window.mozRequestAnimationFrame ||
        window.msRequestAnimationFrame ||
        window.oRequestAnimationFrame;
    var lastScrollTop = $window.scrollTop();

    if (raf) {
        loop();
    }

    function loop() {
        var scrollTop = $window.scrollTop();
        if (lastScrollTop === scrollTop) {
            raf(loop);
            return;
        } else {
            lastScrollTop = scrollTop;
            hideOnScroll(lastScrollTop);
            raf(loop);
        }
    }
  })();
});

</script>
    

<script src="_static/js/vendor/bootstrap.min.js"></script>

</body>
</html>