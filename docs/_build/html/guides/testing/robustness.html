<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>

  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  
  <title>PiML Toolbox</title>
  

  
  <link rel="shortcut icon" href="../../_static/favicon.ico"/>
  

  <link rel="stylesheet" href="../../_static/css/vendor/bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/plot_directive.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/jupyter-sphinx.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/thebelab.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery-rendered-html.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-OERcA2EqjJCMA+/3y+gxIOqMEjwtxJY7qPCqsdltbNJuaOe923+mo//f6V8Qbsw3" crossorigin="anonymous"></script>
<script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
<script src="../../_static/jquery.js"></script>
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/sphinx_highlight.js"></script>
        <script src="../../_static/thebelab-helper.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.1/dist/embed-amd.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
    <script src="../../_static/js/theme.js"></script>

</head>

<body class="wy-body-for-nav">

  


<nav id="navbar" class="sk-docs-navbar navbar navbar-expand-md navbar-light bg-light py-0">
  <div class="container-fluid sk-docs-container px-0">
      <a class="navbar-brand py-0" href="../../index.html">
        <img
          class="sk-brand-img"
          src="../../_static/piml-logo.png"
          alt="logo"/>
      </a>
    <button
      id="sk-navbar-toggler"
      class="navbar-toggler"
      type="button"
      data-toggle="collapse"
      data-target="#navbarSupportedContent"
      aria-controls="navbarSupportedContent"
      aria-expanded="false"
      aria-label="Toggle navigation"
    >
      <span class="navbar-toggler-icon"></span>
    </button>

    <div class="sk-navbar-collapse collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav mr-auto">
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../../install.html">Install</a>
        </li>
		<li class="nav-item">
          <a class="sk-nav-link nav-link" href="../../modules/classes.html">API</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../../user_guide.html">User Guide</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../../auto_examples/index.html">Examples</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../../faq.html">FAQ</a>
        </li>      </ul>
      <div id="searchbox" role="search">
          <div class="searchformwrapper">
          <form class="search" action="../../search.html" method="get">
            <input class="sk-search-text-input" type="text" name="q" aria-labelledby="searchlabel" />
            <input class="sk-search-text-btn" type="submit" value="Go" />
          </form>
          </div>
      </div>
    </div>
  </div>
</nav>
  <div class="d-flex" id="sk-doc-wrapper">
      <input type="checkbox" name="sk-toggle-checkbox" id="sk-toggle-checkbox">
      <label id="sk-sidemenu-toggle" class="sk-btn-toggle-toc btn sk-btn-primary" for="sk-toggle-checkbox">Toggle Menu</label>
      <div id="sk-sidebar-wrapper" class="border-right">
        <div class="sk-sidebar-toc-wrapper">
          <div class="sk-sidebar-toc-logo">
            <a href="../../index.html">
              <img
                class="sk-brand-img"
                src="../../_static/piml-logo.png"
                alt="logo"/>
            </a>
          </div>
          <!--div class="btn-group w-100 mb-2" role="group" aria-label="rellinks">
              <a href="accuracy.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="6.1. Accuracy">Prev</a><a href="../testing.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="6. Outcome Testing">Up</a>
              <a href="resilience.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="6.3. Resilience Test">Next</a>
          </div-->
              <div class="sk-sidebar-toc">
              
                <ul>
                
                
                
                
                
                
                <li>
                  <a href="../../user_guide.html" class="sk-toc-active">User Guide</a>
                </li>
                <ul>
                
                  <li>
                    <a href="../introduction.html" class="">1. Introduction</a>
                    
                  </li>
                
                  <li>
                    <a href="../data.html" class="">2. Data Pipeline</a>
                    
                  </li>
                
                  <li>
                    <a href="../extmodels.html" class="">3. Black-box Models</a>
                    
                  </li>
                
                  <li>
                    <a href="../explainability.html" class="">4. Post-hoc Explainability</a>
                    
                  </li>
                
                  <li>
                    <a href="../models.html" class="">5. Interpretable Models</a>
                    
                  </li>
                
                  <li>
                    <a href="../testing.html" class="sk-toc-active">6. Outcome Testing</a>
                    
                    <ul>
                      
                        <li class="sk-toctree-l3">
                          <a href="accuracy.html">6.1. Accuracy</a>
                        </li>
                      
                        <li class="sk-toctree-l3">
                          <a href="">6.2. Model Robustness</a>
                        </li>
                      
                        <li class="sk-toctree-l3">
                          <a href="resilience.html">6.3. Resilience Test</a>
                        </li>
                      
                        <li class="sk-toctree-l3">
                          <a href="fairness.html">6.4. Fairness Test</a>
                        </li>
                      
                    </ul>
                    
                  </li>
                
                  <li>
                    <a href="../comparison.html" class="">7. Model Comparison</a>
                    
                  </li>
                
                  <li>
                    <a href="../cases.html" class="">8. Case Studies</a>
                    
                  </li>
                
                  <li>
                    <a href="../conclusion.html" class="">9. Conclusion</a>
                    
                  </li>
                
                </ul>
                
                
                
                
                </ul>
              </div>
        </div>
      </div>
      <div id="sk-page-content-wrapper">
        <div class="sk-page-content container-fluid body px-md-3" role="main">
          
  <section id="model-robustness">
<h1><span class="section-number">6.2. </span>Model Robustness<a class="headerlink" href="#model-robustness" title="Permalink to this heading">¶</a></h1>
<p>Widely used in image recognition, natural language processing, self-driving car, and fraud detection, to name a few, the progress of deep learning is astounding! We often rely on performance metrics such as MSE, MAE, ACC, AUC, Recall, Precision,
and F1-score to evaluate our model performance. However, researchers have demonstrated that machine learning models are vulnerable to adversarial examples/noisy data, which may cause the model to predict with high
confidence a wrong class <a class="reference internal" href="#a2018" id="id1"><span>[A2018]</span></a> . In the adversary context, the attacker aims to induce the model (Artificial intelligence system) to return incorrect outputs advantageous for the attacker by adding a carefully imperceivable noise to the input.
If successful, such behavior may lead to unexpected financial losses (Credit, Market, Liquidity) or Non-financial harms (Reputation, Compliance, Legal). On the other hand, random noise is a common cause of most of the data shift/drift that occurs
in real life and may originate from an unexpected change such as the change in consumer behaviors, worlds conflicts, technology breakthroughs, pandemics, socioeconomic and other unpredictable factors that can
dramatically change the input data, the target or the underlying patterns and relations between input and the target variable. We must evaluate all models under distribution shift.</p>
<section id="robustness-and-regularization">
<h2><span class="section-number">6.2.1. </span>Robustness and Regularization<a class="headerlink" href="#robustness-and-regularization" title="Permalink to this heading">¶</a></h2>
<p>Let <span class="math notranslate nohighlight">\(l()\)</span> represents the loss function, <span class="math notranslate nohighlight">\(f_{\theta}()\)</span> the model with parameters <span class="math notranslate nohighlight">\(\theta\)</span> (weigths and bias). Training <span class="math notranslate nohighlight">\(f_{\theta}()\)</span> under regularization consists of minimizing the loss
<span class="math notranslate nohighlight">\(l(f_{\theta}(x),y)+ \lambda  \phi (w)\)</span> where the regularization term <span class="math notranslate nohighlight">\(\phi\)</span> is used to prevent over-fitting. Hence, controlling the bias and variance of the model. A too-limited model may not capture all the information encapsulated
in the data. On the other hand, if the model is too complex, it will capture unnecessary information (noise). In both cases, the model will perform poorly on new data. Sietsma <a class="reference internal" href="#s1991" id="id2"><span>[S1991]</span></a> experimentally demonstrated that training with noise could
improve model robustness, which is also applicable in the context of adversarial robustness, cofirmend by Goodfellow <a class="reference internal" href="#g2014" id="id3"><span>[G2014]</span></a> with adversarial training ( training with adversarial examples). Much later, Bishop <a class="reference internal" href="#b1995" id="id4"><span>[B1995]</span></a> established the connection
between training with noise and regularization and showed that training with noise is equivalent to training with the sum-of-squares error (<span class="math notranslate nohighlight">\(\phi (w) = L_{2} (w)\)</span>) as regularization term. The <span class="math notranslate nohighlight">\(L_{2}\)</span> penalty robustifies the model but
fails to simplify the model. On the other hand, the <span class="math notranslate nohighlight">\(L_{1}\)</span> constraint the model to learn small weights or regularize towards zero, leading to a much simpler model, hence, not over-parameterized.</p>
</section>
<section id="data-shift-input-perturbation">
<h2><span class="section-number">6.2.2. </span>Data shift (Input Perturbation)<a class="headerlink" href="#data-shift-input-perturbation" title="Permalink to this heading">¶</a></h2>
<p>This section briefly describes key perturbation approaches used in PiML to simulate the data distribution shift. Perturbed input will be used for model robustness evaluation.</p>
<ul class="simple">
<li><p><strong>Perturbation of continuous variables</strong>: We added random Gaussian noise with mean 0 and variance <span class="math notranslate nohighlight">\(λ(variance(X))\)</span> to the input <span class="math notranslate nohighlight">\(X\)</span> to evaluate for robustness, of which <span class="math notranslate nohighlight">\(λ\)</span>) is used to
vary the variance, hence the noise level.</p></li>
<li><p><strong>Discrete Variable Perturbation</strong>: The perturbation of discrete random variables is much more complex. To facilitate our understanding, consider a sorted discrete variable <span class="math notranslate nohighlight">\(X\)</span> with values <span class="math notranslate nohighlight">\([1, 2, 2, 3, 30, 50,50, 50]\)</span> and
corresponding Quantiles vector <span class="math notranslate nohighlight">\(Q: [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\)</span>. If we perturb <span class="math notranslate nohighlight">\(Q\)</span> with a small random noise <span class="math notranslate nohighlight">\(\epsilon\)</span> such that <span class="math notranslate nohighlight">\(\epsilon\)</span> follows the uniform distribution
(<span class="math notranslate nohighlight">\(U(-0.5*perturb \_ step*noise \_ level, 0.5*perturb \_ step*noise \_ level)\)</span>). The user may adjust the perturbation step (<code class="docutils literal notranslate"><span class="pre">perturb_step</span></code>) and the <code class="docutils literal notranslate"><span class="pre">noise_level</span></code>, which can take the values 1,2,3, or 4 corresponding to the
four noise levels. For instance, in <span class="math notranslate nohighlight">\(Q\)</span>, if the perturbed value of 0.3 (corresponding to 2 in <span class="math notranslate nohighlight">\(X\)</span>) is 0.36, we round 0.36 to 0.4 (which corresponds to 3 in <span class="math notranslate nohighlight">\(X\)</span>), then we conclude that the perturbed value of 2 is 3.</p></li>
<li><p><strong>Categorical Variable Perturbation</strong>: We perturb a sample with probability <span class="math notranslate nohighlight">\(p\)</span> (<code class="docutils literal notranslate"><span class="pre">perturb_size</span></code>) by standard deviation of categorical feature.</p></li>
</ul>
</section>
<section id="robustness-test">
<h2><span class="section-number">6.2.3. </span>Robustness Test<a class="headerlink" href="#robustness-test" title="Permalink to this heading">¶</a></h2>
<section id="binary-classification-tasks">
<h3><span class="section-number">6.2.3.1. </span>Binary classification tasks<a class="headerlink" href="#binary-classification-tasks" title="Permalink to this heading">¶</a></h3>
<p>We consider a binary classification task on the  TaiwanCredit data from UCI repository. The response to this classification problem is ‘FlagDefault’.
Let’s start by training four separate models; we then demonstrate how to use PiML to asses individual robustness or compare models in terms of robustness (this approach can be extended to
multiple models). It is important to note that PiMl only focuses on robustness to random noise, not adversarial robustness.</p>
<section id="moodels-instantiation-and-training">
<h4><span class="section-number">6.2.3.1.1. </span>Moodels instantiation and training<a class="headerlink" href="#moodels-instantiation-and-training" title="Permalink to this heading">¶</a></h4>
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">ipywidgets</span>
<span class="k">with</span> <span class="n">ipywidgets</span><span class="o">.</span><span class="n">Output</span><span class="p">():</span>
  <span class="kn">from</span> <span class="nn">piml</span> <span class="kn">import</span> <span class="n">Experiment</span>
  <span class="kn">from</span> <span class="nn">piml.models</span> <span class="kn">import</span> <span class="n">FIGSClassifier</span>
  <span class="kn">from</span> <span class="nn">piml.models</span> <span class="kn">import</span> <span class="n">ReluDNNClassifier</span>
  <span class="kn">from</span> <span class="nn">piml.models</span> <span class="kn">import</span> <span class="n">GAMINetClassifier</span>
  <span class="n">exp</span> <span class="o">=</span> <span class="n">Experiment</span><span class="p">()</span>
  <span class="n">exp</span><span class="o">.</span><span class="n">data_loader</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="s1">&#39;TaiwanCredit&#39;</span><span class="p">)</span>
  <span class="n">exp</span><span class="o">.</span><span class="n">data_summary</span><span class="p">(</span><span class="n">feature_exclude</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;LIMIT_BAL&quot;</span><span class="p">,</span> <span class="s2">&quot;SEX&quot;</span><span class="p">,</span> <span class="s2">&quot;EDUCATION&quot;</span><span class="p">,</span> <span class="s2">&quot;MARRIAGE&quot;</span><span class="p">,</span> <span class="s2">&quot;AGE&quot;</span><span class="p">],</span> <span class="n">feature_type</span><span class="o">=</span><span class="p">{})</span>
  <span class="n">exp</span><span class="o">.</span><span class="n">data_prepare</span><span class="p">(</span><span class="n">target</span><span class="o">=</span><span class="s1">&#39;FlagDefault&#39;</span><span class="p">,</span> <span class="n">task_type</span><span class="o">=</span><span class="s1">&#39;Classification&#39;</span><span class="p">,</span> <span class="n">test_ratio</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
</div>
</div>
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">exp</span><span class="o">.</span><span class="n">model_train</span><span class="p">(</span><span class="n">FIGSClassifier</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">splitter</span><span class="o">=</span><span class="s1">&#39;best&#39;</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                               <span class="n">min_impurity_decrease</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.0002</span><span class="p">,</span>
                               <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">),</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;FIGS&quot;</span><span class="p">)</span>
<span class="n">exp</span><span class="o">.</span><span class="n">model_train</span><span class="p">(</span><span class="n">ReluDNNClassifier</span><span class="p">(</span><span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">60</span><span class="p">,</span><span class="mi">60</span><span class="p">),</span> <span class="n">l1_reg</span><span class="o">=</span><span class="mf">0.0002</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>
                                  <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.0002</span><span class="p">),</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;ReluDNN_A&quot;</span><span class="p">)</span>
<span class="n">exp</span><span class="o">.</span><span class="n">model_train</span><span class="p">(</span><span class="n">ReluDNNClassifier</span><span class="p">(</span><span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">60</span><span class="p">,</span><span class="mi">60</span><span class="p">),</span> <span class="n">l1_reg</span><span class="o">=</span><span class="mf">0.003</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>
                                  <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.0002</span><span class="p">),</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;ReluDNN_B&quot;</span><span class="p">)</span>
<span class="n">exp</span><span class="o">.</span><span class="n">model_train</span><span class="p">(</span><span class="n">GAMINetClassifier</span><span class="p">(</span><span class="n">interact_num</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">loss_threshold</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
                                  <span class="n">subnet_size_main_effect</span><span class="o">=</span><span class="p">[</span><span class="mi">20</span><span class="p">],</span>
                                  <span class="n">subnet_size_interaction</span><span class="o">=</span><span class="p">[</span><span class="mi">20</span><span class="p">,</span><span class="mi">20</span><span class="p">]),</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;GAMINet&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
</div>
</div>
</section>
<section id="model-performance-on-natural-data-no-perturbation-appied">
<h4><span class="section-number">6.2.3.1.2. </span>Model performance on natural data (No perturbation appied)<a class="headerlink" href="#model-performance-on-natural-data-no-perturbation-appied" title="Permalink to this heading">¶</a></h4>
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">exp</span><span class="o">.</span><span class="n">model_compare</span><span class="p">(</span><span class="n">models</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;FIGS&quot;</span><span class="p">,</span><span class="s2">&quot;ReluDNN_A&quot;</span><span class="p">,</span><span class="s2">&quot;ReluDNN_B&quot;</span><span class="p">,</span><span class="s2">&quot;GAMINet&quot;</span><span class="p">],</span>
                  <span class="n">show</span><span class="o">=</span><span class="s1">&#39;accuracy_auc&#39;</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
</div>
</div>
<figure class="align-left">
<a class="reference external image-reference" href="../../auto_examples/diagnostics/plot_3_robustness_001.html"><img alt="../../_images/sphx_glr_plot_3_robustness_001.png" src="../../_images/sphx_glr_plot_3_robustness_001.png" style="width: 400.0px; height: 320.0px;" /></a>
</figure>
<p>Considering AUC as our evaluation criteria, two models (ReluDNN_A and GAMINet) recorded a comparable performance. However, are these models truly comparable? In the following section, we demonstrated how to use PiML to
assess the robustness of these models under different noise levels. Assessing models under unexpected changes is strongly recommended to minimize the risks after deployment.</p>
</section>
<section id="id5">
<h4><span class="section-number">6.2.3.1.3. </span>Model Robustness<a class="headerlink" href="#id5" title="Permalink to this heading">¶</a></h4>
<p>We first consider the performance of individual models. In addition, we can also compare the performance of many models at the same time (in this demo, we consider four models). The
robustness assessment helps identify a more robust and suitable model for a particular task.</p>
<p>PiML offers the flexibility to choose a perturbation step size. The plot below is under the default step size (0.1).</p>
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">exp</span><span class="o">.</span><span class="n">model_diagnose</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;ReluDNN_A&quot;</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="s1">&#39;robustness&#39;</span><span class="p">,</span>
                   <span class="n">perturb_features</span><span class="o">=</span><span class="s1">&#39;All Features&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
</div>
</div>
<figure class="align-left">
<a class="reference external image-reference" href="../../auto_examples/diagnostics/plot_3_robustness_002.html"><img alt="../../_images/sphx_glr_plot_3_robustness_002.png" src="../../_images/sphx_glr_plot_3_robustness_002.png" style="width: 200.0px; height: 160.0px;" /></a>
</figure>
<figure class="align-left">
<a class="reference external image-reference" href="../../auto_examples/diagnostics/plot_3_robustness_003.html"><img alt="../../_images/sphx_glr_plot_3_robustness_003.png" src="../../_images/sphx_glr_plot_3_robustness_003.png" style="width: 200.0px; height: 160.0px;" /></a>
</figure>
<p>The plot on the right represents the model performance when we perturb the input. On the other hand, the left plot  has the models’ performance evaluated on the <span class="math notranslate nohighlight">\(30\%\)</span> worst samples.  At noise level 0.0, no perturbation is applied.
The worst sample AUC is approximately 0.315, and the models’ performance on the testing data is 0.793. Under perturbation, the worst samples recorded a significant drop in AUC. The worst sample scenario may help asses the model under the
worst-case scenario. In the following plot, we consider the step size of 0.01.</p>
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">exp</span><span class="o">.</span><span class="n">model_diagnose</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;ReluDNN_A&quot;</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="s1">&#39;robustness&#39;</span><span class="p">,</span>
                   <span class="n">perturb_size</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
                   <span class="n">perturb_features</span><span class="o">=</span><span class="s1">&#39;All Features&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
</div>
</div>
<figure class="align-left">
<a class="reference external image-reference" href="../../auto_examples/diagnostics/plot_3_robustness_004.html"><img alt="auto_examples/diagnostics/images/sphx_glr_plot_3_robustness_004.png" src="auto_examples/diagnostics/images/sphx_glr_plot_3_robustness_004.png" /></a>
</figure>
<figure class="align-left">
<a class="reference external image-reference" href="../../auto_examples/diagnostics/plot_3_robustness_005.html"><img alt="auto_examples/diagnostics/images/sphx_glr_plot_3_robustness_005.png" src="auto_examples/diagnostics/images/sphx_glr_plot_3_robustness_005.png" /></a>
</figure>
<p>We should be cautious about selecting a model for a particular task. In the following, we demonstrate how to use PiML to compare the robustness performance of different models. We consider comparing
completely different types of models and similar model architectures but trained under different parameters. The sample with the low AUC is consider the worst sample. We can use PiML to evaluate the model
performance on the selected worst samples by setting the parameter <code class="docutils literal notranslate"><span class="pre">show</span></code> to <code class="docutils literal notranslate"><span class="pre">robustness_perf_worst</span></code>. The default perturbation method in the robustness test is ‘raw’, which consists of adding normal noise directly on covariates for perturbation
(Noise applied on continuous variables).</p>
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">exp</span><span class="o">.</span><span class="n">model_compare</span><span class="p">(</span><span class="n">models</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;FIGS&quot;</span><span class="p">,</span><span class="s2">&quot;ReluDNN_A&quot;</span><span class="p">,</span> <span class="s2">&quot;ReluDNN_B&quot;</span><span class="p">,</span> <span class="s2">&quot;GAMINet&quot;</span><span class="p">],</span>
                  <span class="n">show</span><span class="o">=</span><span class="s1">&#39;robustness_perf_worst&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
</div>
</div>
<figure class="align-left">
<a class="reference external image-reference" href="../../auto_examples/diagnostics/plot_3_robustness_006.html"><img alt="auto_examples/diagnostics/images/sphx_glr_plot_3_robustness_006.png" src="auto_examples/diagnostics/images/sphx_glr_plot_3_robustness_006.png" /></a>
</figure>
<p>The plot above compares models under the worst-performing test samples. In this context, we identify the <span class="math notranslate nohighlight">\(30\%\)</span> worst performing test sample (Low performing test samples are test samples with low AUC), then apply a perturbation. Under
perturbation (distribution drift), the plot above indicates that model <code class="docutils literal notranslate"><span class="pre">ReluDNN_B</span></code> will perform better on the worst sample. The worst-performing model is <code class="docutils literal notranslate"><span class="pre">FIGS</span></code>. We may not only compare the Robustness performance under the worst-case scenario.
For general robustness, set <code class="docutils literal notranslate"><span class="pre">show</span></code> to <code class="docutils literal notranslate"><span class="pre">robustness_perf</span></code> as follows.</p>
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">exp</span><span class="o">.</span><span class="n">model_compare</span><span class="p">(</span><span class="n">models</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;FIGS&quot;</span><span class="p">,</span><span class="s2">&quot;ReluDNN_A&quot;</span><span class="p">,</span><span class="s2">&quot;ReluDNN_B&quot;</span><span class="p">,</span><span class="s2">&quot;GAMINet&quot;</span><span class="p">],</span>
                  <span class="n">show</span><span class="o">=</span><span class="s1">&#39;robustness_perf&#39;</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
</div>
</div>
<figure class="align-left">
<a class="reference external image-reference" href="../../auto_examples/diagnostics/plot_3_robustness_007.html"><img alt="auto_examples/diagnostics/images/sphx_glr_plot_3_robustness_007.png" src="auto_examples/diagnostics/images/sphx_glr_plot_3_robustness_007.png" /></a>
</figure>
<p>To perturb discrete variables, use the ‘quantile’ perturbation method, as illustrated below.</p>
<div class="jupyter_cell jupyter_container docutils container">
<div class="cell_input code_cell docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">exp</span><span class="o">.</span><span class="n">model_compare</span><span class="p">(</span><span class="n">models</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;FIGS&quot;</span><span class="p">,</span><span class="s2">&quot;ReluDNN_A&quot;</span><span class="p">,</span><span class="s2">&quot;ReluDNN_B&quot;</span><span class="p">,</span><span class="s2">&quot;GAMINet&quot;</span><span class="p">],</span>
                  <span class="n">perturb_method</span> <span class="o">=</span> <span class="s1">&#39;quantile&#39;</span><span class="p">,</span>
                  <span class="n">show</span><span class="o">=</span><span class="s1">&#39;robustness_perf&#39;</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
</div>
</div>
<figure class="align-left">
<a class="reference external image-reference" href="../../auto_examples/diagnostics/plot_3_robustness_008.html"><img alt="auto_examples/diagnostics/images/sphx_glr_plot_3_robustness_008.png" src="auto_examples/diagnostics/images/sphx_glr_plot_3_robustness_008.png" /></a>
</figure>
<p>The plot above compares models under different noise levels. In this case, the perturbation is applied to all the variables. Cleary, models <code class="docutils literal notranslate"><span class="pre">ReluDNN_A</span></code> and <code class="docutils literal notranslate"><span class="pre">GAMINet</span></code> are not
comparable. Hence, contradicted the observation made under natural evaluation.  Model <code class="docutils literal notranslate"><span class="pre">ReluDNN_A</span></code> recorded a better robust performance, followed by <code class="docutils literal notranslate"><span class="pre">ReluDNN_B</span></code>. In addition,  the plot above indicates that we should
always consider different parameter settings as they can influence the model’s robustness. For instance, models <code class="docutils literal notranslate"><span class="pre">ReluDNN_A</span></code> and <code class="docutils literal notranslate"><span class="pre">ReluDNN_B</span></code> recorded different robust performances.
However, they share the same architecture but are trained under different regularization strengths.</p>
</section>
</section>
<section id="regression-tasks">
<h3><span class="section-number">6.2.3.2. </span>Regression tasks.<a class="headerlink" href="#regression-tasks" title="Permalink to this heading">¶</a></h3>
<p>For a regression task, refer to the example 2.</p>
</section>
<section id="examples">
<h3><span class="section-number">6.2.3.3. </span>Examples<a class="headerlink" href="#examples" title="Permalink to this heading">¶</a></h3>
<div class="topic">
<p class="topic-title">Example 1</p>
<p>The example below demonstrates how to use PiML with its high-code APIs for developing machine learning models for the BikeSharing data from UCI repository, which consists of 17,389
samples of hourly counts of rental bikes in Capital bikeshare system; see details <a class="reference external" href="https://archive.ics.uci.edu/ml/datasets/bike+sharing+dataset">here</a>. The response <code class="docutils literal notranslate"><span class="pre">cnt</span></code> (hourly bike rental counts) is continuous and it is a regression problem.</p>
<ul class="simple">
<li><p><a class="reference internal" href="../../auto_examples/diagnostics/plot_3_robustness.html#sphx-glr-auto-examples-diagnostics-plot-3-robustness-py"><span class="std std-ref">Robustness: Classification</span></a></p></li>
</ul>
</div>
<div class="topic">
<p class="topic-title">Example 2</p>
<p>We consider a binary classification task on the  TaiwanCredit data from UCI repository, which consists of 30,000 clients’ credit cards in Taiwan from 200504 to 200509; see details here
<a class="reference external" href="https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients">TaiwanCreditData</a> . The data can be loaded from PiML and subject to slight preprocessing. The response to this classification problem is ‘FlagDefault’.</p>
<ul class="simple">
<li><p><a class="reference internal" href="../../auto_examples/diagnostics/plot_2_robustness.html#sphx-glr-auto-examples-diagnostics-plot-2-robustness-py"><span class="std std-ref">Robustness:  Regression</span></a></p></li>
</ul>
</div>
<div class="topic">
<p class="topic-title">References</p>
<dl class="citation">
<dt class="label" id="a2018"><span class="brackets"><a class="fn-backref" href="#id1">A2018</a></span></dt>
<dd><p>Athanasios Voulodimos, Nikolaos Doulamis, Anastasios Doulamis, and Eftychios Protopapadakis.
<a class="reference external" href="DeepLearningforComputerVision:ABriefReview(hindawi.com)">Deep learning for computer vision: A brief review.</a>,
Computational intelligence and neuroscience, vol. 2018, 2018.</p>
</dd>
<dt class="label" id="s1991"><span class="brackets"><a class="fn-backref" href="#id2">S1991</a></span></dt>
<dd><p>Sietsma, Jocelyn, and Robert JF Dow.
<a class="reference external" href="https://www.sciencedirect.com/science/article/abs/pii/0893608091900332">Creating artificial neural networks that generalize.</a>,
Neural networks 4.1 (1991): 67-79.</p>
</dd>
<dt class="label" id="g2014"><span class="brackets"><a class="fn-backref" href="#id3">G2014</a></span></dt>
<dd><p>Goodfellow, Ian J., Jonathon Shlens, and Christian Szegedy.
<a class="reference external" href="https://arxiv.org/abs/1412.6572">Explaining and harnessing adversarial examples.</a>,
arXiv preprint arXiv:1412.6572 (2014).</p>
</dd>
<dt class="label" id="b1995"><span class="brackets"><a class="fn-backref" href="#id4">B1995</a></span></dt>
<dd><p>Bishop, Chris M.
<a class="reference external" href="https://ieeexplore.ieee.org/abstract/document/6796505">Training with noise is equivalent to Tikhonov regularization.</a>,
Neural computation 7.1 (1995): 108-116.</p>
</dd>
</dl>
</div>
</section>
</section>
</section>


        </div>
      <div class="container">
        <footer class="sk-content-footer">
              &copy; Copyright 2022-, PiML-Toolbox authors.
            <a href="../../_sources/guides/testing/robustness.rst.txt" rel="nofollow">Show this page source</a>
        </footer>
      </div>
    </div>
  </div>


  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(false);
      });
      
      const tooltipTriggerList = document.querySelectorAll('[data-bs-toggle="tooltip"]')
      const tooltipList = [...tooltipTriggerList].map(tooltipTriggerEl => new bootstrap.Tooltip(tooltipTriggerEl))
  </script>

<script>
$(document).ready(function() {
    /* Add a [>>>] button on the top-right corner of code samples to hide
     * the >>> and ... prompts and the output and thus make the code
     * copyable. */
    var div = $('.highlight-python .highlight,' +
                '.highlight-python3 .highlight,' +
                '.highlight-pycon .highlight,' +
		'.highlight-default .highlight')
    var pre = div.find('pre');

    // get the styles from the current theme
    pre.parent().parent().css('position', 'relative');
    var hide_text = 'Hide prompts and outputs';
    var show_text = 'Show prompts and outputs';

    // create and add the button to all the code blocks that contain >>>
    div.each(function(index) {
        var jthis = $(this);
        if (jthis.find('.gp').length > 0) {
            var button = $('<span class="copybutton">&gt;&gt;&gt;</span>');
            button.attr('title', hide_text);
            button.data('hidden', 'false');
            jthis.prepend(button);
        }
        // tracebacks (.gt) contain bare text elements that need to be
        // wrapped in a span to work with .nextUntil() (see later)
        jthis.find('pre:has(.gt)').contents().filter(function() {
            return ((this.nodeType == 3) && (this.data.trim().length > 0));
        }).wrap('<span>');
    });

    // define the behavior of the button when it's clicked
    $('.copybutton').click(function(e){
        e.preventDefault();
        var button = $(this);
        if (button.data('hidden') === 'false') {
            // hide the code output
            button.parent().find('.go, .gp, .gt').hide();
            button.next('pre').find('.gt').nextUntil('.gp, .go').css('visibility', 'hidden');
            button.css('text-decoration', 'line-through');
            button.attr('title', show_text);
            button.data('hidden', 'true');
        } else {
            // show the code output
            button.parent().find('.go, .gp, .gt').show();
            button.next('pre').find('.gt').nextUntil('.gp, .go').css('visibility', 'visible');
            button.css('text-decoration', 'none');
            button.attr('title', hide_text);
            button.data('hidden', 'false');
        }
    });

	/*** Add permalink buttons next to glossary terms ***/
	$('dl.glossary > dt[id]').append(function() {
		return ('<a class="headerlink" href="#' +
			    this.getAttribute('id') +
			    '" title="Permalink to this term">¶</a>');
	});
  /*** Hide navbar when scrolling down ***/
  // Returns true when headerlink target matches hash in url
  (function() {
    hashTargetOnTop = function() {
        var hash = window.location.hash;
        if ( hash.length < 2 ) { return false; }

        var target = document.getElementById( hash.slice(1) );
        if ( target === null ) { return false; }

        var top = target.getBoundingClientRect().top;
        return (top < 2) && (top > -2);
    };

    // Hide navbar on load if hash target is on top
    var navBar = document.getElementById("navbar");
    var navBarToggler = document.getElementById("sk-navbar-toggler");
    var navBarHeightHidden = "-" + navBar.getBoundingClientRect().height + "px";
    var $window = $(window);

    hideNavBar = function() {
        navBar.style.top = navBarHeightHidden;
    };

    showNavBar = function() {
        navBar.style.top = "0";
    }

    if (hashTargetOnTop()) {
        hideNavBar()
    }

    var prevScrollpos = window.pageYOffset;
    hideOnScroll = function(lastScrollTop) {
        if (($window.width() < 768) && (navBarToggler.getAttribute("aria-expanded") === 'true')) {
            return;
        }
        if (lastScrollTop > 2 && (prevScrollpos <= lastScrollTop) || hashTargetOnTop()){
            hideNavBar()
        } else {
            showNavBar()
        }
        prevScrollpos = lastScrollTop;
    };

    /*** high performance scroll event listener***/
    var raf = window.requestAnimationFrame ||
        window.webkitRequestAnimationFrame ||
        window.mozRequestAnimationFrame ||
        window.msRequestAnimationFrame ||
        window.oRequestAnimationFrame;
    var lastScrollTop = $window.scrollTop();

    if (raf) {
        loop();
    }

    function loop() {
        var scrollTop = $window.scrollTop();
        if (lastScrollTop === scrollTop) {
            raf(loop);
            return;
        } else {
            lastScrollTop = scrollTop;
            hideOnScroll(lastScrollTop);
            raf(loop);
        }
    }
  })();
});

</script>
    

<script src="_static/js/vendor/bootstrap.min.js"></script>

</body>
</html>